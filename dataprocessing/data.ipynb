{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c6bda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 15:31:55.685788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-08 15:31:55.793219: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-08 15:31:55.793231: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-08 15:31:56.258633: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-08 15:31:56.258681: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-08 15:31:56.258687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5203646e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193195/520090854.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_o = df_o.drop(['game_id', 'Team_abbrev', 'pass_yds_bonus', 'rush_yds_bonus', 'rec_yds_bonus', 'Total_DKP', 'Off_DKP', 'Total_FDP', 'Off_FDP', 'Total_SDP', 'Off_SDP', 'offense', 'off_pct', 'vis_score', 'home_score', 'OT', 'Roof', 'Surface', 'Temperature', 'Humidity', 'Wind_Speed', 'Vegas_Line', 'Vegas_Favorite', 'Over_Under'], 1)\n"
     ]
    }
   ],
   "source": [
    "df_o = pd.read_csv(\"nfl_pass_rush_receive_raw_data.csv\")\n",
    "df_o = df_o.drop(['game_id', 'Team_abbrev', 'pass_yds_bonus', 'rush_yds_bonus', 'rec_yds_bonus', 'Total_DKP', 'Off_DKP', 'Total_FDP', 'Off_FDP', 'Total_SDP', 'Off_SDP', 'offense', 'off_pct', 'vis_score', 'home_score', 'OT', 'Roof', 'Surface', 'Temperature', 'Humidity', 'Wind_Speed', 'Vegas_Line', 'Vegas_Favorite', 'Over_Under'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d1c9a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_date(s):\n",
    "    return datetime.datetime(*list(map(int, s.split('-'))))\n",
    "str_to_date = np.vectorize(str_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a5792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_days(t):\n",
    "    return t.days\n",
    "get_days = np.vectorize(get_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad3e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193195/1957130345.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_o = df_o.drop('game_date', 1)\n"
     ]
    }
   ],
   "source": [
    "start = str_to_date(df_o.iloc[0]['game_date'])\n",
    "weeks_o = get_days(str_to_date(df_o['game_date']) - start) // 7 + 1\n",
    "df_o['week'] = weeks_o\n",
    "df_o = df_o.drop('game_date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c82f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = df_o['player_id'].unique()\n",
    "num_players_o = len(ids)\n",
    "id_to_num = dict(zip(ids, np.arange(num_players_o)))\n",
    "num_weeks = weeks_o[-1]\n",
    "has_week_o = np.zeros([num_players_o, num_weeks])\n",
    "for id, week in zip(df_o['player_id'], df_o['week']):\n",
    "    has_week_o[id_to_num[id], week - 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6a1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_info = {}\n",
    "for id, name, pos, team in zip(df_o['player_id'], df_o['player'], df_o['pos'], df_o['team']):\n",
    "    id_to_info[id] = (name, pos, team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0071048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = [df_o]\n",
    "for id in ids:\n",
    "    for i in range(num_weeks):\n",
    "        if has_week_o[id_to_num[id], i] == 0:\n",
    "            df_new.append(pd.DataFrame([[id, '', id_to_info[id][0]] + [''] + [0] * 24 + ['']+ [0] * 13 + [''] * 2 + [i + 1]], columns=df_o.columns))\n",
    "df_o = pd.concat(df_new)\n",
    "df_o.to_csv(\"offense_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c54cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comb_rush_play'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_o.columns[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffd011d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = []\n",
    "for id, (name, pos, team) in id_to_info.items():\n",
    "    df_new.append(pd.DataFrame([[id, name, pos, team if len(team) == 3 else '']], columns=['player_id', 'player', 'pos', 'team']))\n",
    "df_player_o = pd.concat(df_new)\n",
    "df_player_o.to_csv(\"offense_players_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f190a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193195/1955825311.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_k = df_k.drop(['game_id', 'Total_DKP', 'Total_FDP', 'Total_SDP', 'vis_score', 'home_score', 'OT', 'Roof', 'Surface',\n"
     ]
    }
   ],
   "source": [
    "df_k = pd.read_csv('nfl_kicking_raw_data.csv')\n",
    "df_k = df_k.drop(['game_id', 'Total_DKP', 'Total_FDP', 'Total_SDP', 'vis_score', 'home_score', 'OT', 'Roof', 'Surface',\n",
    "       'Temperature', 'Humidity', 'Wind_Speed', 'Vegas_Line', 'Vegas_Favorite',\n",
    "       'Over_Under'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae902dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_193195/3774448750.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_k = df_k.drop('game_date', 1)\n"
     ]
    }
   ],
   "source": [
    "weeks_k = get_days(str_to_date(df_k['game_date']) - start) // 7 + 1\n",
    "df_k['week'] = weeks_k\n",
    "df_k = df_k.drop('game_date', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2215658",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = df_k['player'].unique()\n",
    "num_players_k = len(names)\n",
    "name_to_num = dict(zip(names, np.arange(num_players_k)))\n",
    "has_week_k = np.zeros([num_players_k, num_weeks])\n",
    "for name, week in zip(df_k['player'], df_k['week']):\n",
    "    has_week_k[name_to_num[name], week - 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77d14a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_team = {}\n",
    "for name, team in zip(df_k['player'], df_k['Off_abbrev']):\n",
    "    name_to_team[name] = team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e747c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = [df_k]\n",
    "for name in names:\n",
    "    for i in range(num_weeks):\n",
    "        if has_week_k[name_to_num[name], i] == 0:\n",
    "            df_new.append(pd.DataFrame([[name_to_team[name], ''] + [0] * 10 + [name] + [''] * 2 + [i + 1]], columns=df_k.columns))\n",
    "df_k = pd.concat(df_new)\n",
    "df_k.to_csv('kicking_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d38708fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_player_k = pd.DataFrame.from_dict(name_to_team, 'index').reset_index()\n",
    "df_player_k.columns = ['player', 'Off_abbrev']\n",
    "df_player_k.to_csv('kicking_players_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ff]",
   "language": "python",
   "name": "conda-env-ff-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
